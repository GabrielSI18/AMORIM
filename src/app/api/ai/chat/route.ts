import { streamText, convertToModelMessages, UIMessage } from 'ai';
import { defaultModels, canUseProvider } from '@/lib/ai';
import type { AIProvider } from '@/types/ai';

/**
 * POST /api/ai/chat
 * 
 * ‚úÖ Chat conversacional com hist√≥rico
 * 
 * Endpoint para chat com streaming de respostas usando Vercel AI SDK
 * Suporta 3 providers: groq (gratuito - padr√£o), openai, deepinfra (avan√ßado)
 * 
 * Casos de uso:
 * - Assistente virtual
 * - Chatbot de suporte
 * - Conversas com contexto
 * 
 * @example
 * ```typescript
 * const response = await fetch('/api/ai/chat', {
 *   method: 'POST',
 *   body: JSON.stringify({
 *     messages: [
 *       { role: 'user', content: 'Ol√°!' }
 *     ],
 *     provider: 'groq' // opcional
 *   })
 * });
 * ```
 */
export async function POST(req: Request) {
  try {
    console.log('\nüöÄ [AI Chat] Nova requisi√ß√£o');
    
    const body = await req.json();
    console.log('üì¶ [AI Chat] Body recebido:', JSON.stringify({
      messagesCount: body.messages?.length,
      provider: body.provider,
      model: body.model,
    }));
    
    const { 
      messages, 
      provider = 'groq',
      model,
    }: { 
      messages: UIMessage[];
      provider?: AIProvider;
      model?: string;
    } = body;

    console.log('üìã [AI Chat] Par√¢metros finais:', { provider, model, messagesCount: messages?.length });

    // Valida√ß√£o b√°sica
    if (!messages || !Array.isArray(messages)) {
      console.error('‚ùå [AI Chat] Messages inv√°lido');
      return Response.json(
        { error: 'Campo "messages" √© obrigat√≥rio e deve ser um array' },
        { status: 400 }
      );
    }

    console.log('üîç [AI Chat] Iniciando valida√ß√£o do provider...');
    // Validar se provider pode ser usado
    const validation = canUseProvider(provider);
    console.log('‚úÖ [AI Chat] Resultado da valida√ß√£o:', validation);
    
    if (!validation.canUse) {
      console.error('‚ùå [AI Chat] Provider n√£o pode ser usado:', validation.error);
      return Response.json(
        { 
          error: validation.error,
          code: 'PROVIDER_NOT_CONFIGURED',
          provider,
        },
        { status: 403 }
      );
    }

    // Selecionar modelo
    const selectedModel = model 
      ? (provider === 'groq' && model.includes('groq.') ? model : model)
      : (provider === 'groq' ? defaultModels.free
        : provider === 'deepinfra' ? defaultModels.advanced
        : defaultModels.standard);

    console.log('ü§ñ [AI Chat] Modelo selecionado:', selectedModel);
    console.log('üí¨ [AI Chat] Iniciando streaming...');

    // Gera resposta com streaming
    const result = streamText({
      model: selectedModel,
      messages: convertToModelMessages(messages),
      temperature: 0.7,
    });
    
    console.log('‚úÖ [AI Chat] Stream iniciado com sucesso!');

    return result.toUIMessageStreamResponse();
  } catch (error) {
    console.error('‚ùå [AI Chat] Erro:', error);
    
    return Response.json(
      { error: 'Erro ao processar chat' },
      { status: 500 }
    );
  }
}
